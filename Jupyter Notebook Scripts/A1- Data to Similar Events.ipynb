{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "altered-montreal",
   "metadata": {
    "papermill": {
     "duration": 0.009678,
     "end_time": "2022-04-17T03:09:38.920247",
     "exception": false,
     "start_time": "2022-04-17T03:09:38.910569",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "gentle-costa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T03:09:38.944826Z",
     "iopub.status.busy": "2022-04-17T03:09:38.944091Z",
     "iopub.status.idle": "2022-04-17T03:09:39.009050Z",
     "shell.execute_reply": "2022-04-17T03:09:39.008356Z",
     "shell.execute_reply.started": "2022-04-16T01:01:31.180811Z"
    },
    "papermill": {
     "duration": 0.080007,
     "end_time": "2022-04-17T03:09:39.009216",
     "exception": false,
     "start_time": "2022-04-17T03:09:38.929209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input1</th>\n",
       "      <th>Input2</th>\n",
       "      <th>Input3</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.659116</td>\n",
       "      <td>4.673695</td>\n",
       "      <td>1.231898</td>\n",
       "      <td>-1.010633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.172297</td>\n",
       "      <td>0.308095</td>\n",
       "      <td>6.197296</td>\n",
       "      <td>0.140169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.620350</td>\n",
       "      <td>3.752477</td>\n",
       "      <td>3.010036</td>\n",
       "      <td>0.014108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.269573</td>\n",
       "      <td>3.173038</td>\n",
       "      <td>6.019555</td>\n",
       "      <td>-0.016590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.946378</td>\n",
       "      <td>3.264015</td>\n",
       "      <td>2.245954</td>\n",
       "      <td>1.222183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Input1    Input2    Input3    Output\n",
       "0  2.659116  4.673695  1.231898 -1.010633\n",
       "1  6.172297  0.308095  6.197296  0.140169\n",
       "2  1.620350  3.752477  3.010036  0.014108\n",
       "3  6.269573  3.173038  6.019555 -0.016590\n",
       "4  3.946378  3.264015  2.245954  1.222183"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv_path = '../input/toy-dataset-for-regression-and-uq/Data3_Train.csv'\n",
    "test_csv_path = '../input/toy-dataset-for-regression-and-uq/Data3_Test.csv'\n",
    "val_csv_path = '../input/toy-dataset-for-regression-and-uq/Data3_Val.csv'\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "val_df = pd.read_csv(val_csv_path)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-pizza",
   "metadata": {
    "papermill": {
     "duration": 0.008813,
     "end_time": "2022-04-17T03:09:39.027644",
     "exception": false,
     "start_time": "2022-04-17T03:09:39.018831",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Arranging and Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "protected-guest",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T03:09:39.770556Z",
     "iopub.status.busy": "2022-04-17T03:09:39.769406Z",
     "iopub.status.idle": "2022-04-17T03:09:42.057316Z",
     "shell.execute_reply": "2022-04-17T03:09:42.056205Z",
     "shell.execute_reply.started": "2022-04-16T01:01:31.261058Z"
    },
    "papermill": {
     "duration": 3.020755,
     "end_time": "2022-04-17T03:09:42.057548",
     "exception": false,
     "start_time": "2022-04-17T03:09:39.036793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "tensor(1.4626) tensor(-1.4431) tensor([6.2822, 6.2817, 6.2823]) tensor([4.0563e-04, 6.2234e-05, 9.0123e-04])\n",
      "tensor([6.2818, 6.2816, 6.2814]) tensor(2.9057)\n"
     ]
    }
   ],
   "source": [
    "input_=[]\n",
    "output_=[]\n",
    "for row in train_df.iloc:\n",
    "    input_.append((row[0:len(row)-1]).astype(float))\n",
    "    output_.append(row[-1])\n",
    "    \n",
    "i_val=[]\n",
    "o_val=[]\n",
    "for row in val_df.iloc:\n",
    "    i_val.append((row[0:len(row)-1]).astype(float))\n",
    "    o_val.append(row[-1])\n",
    "    \n",
    "num_input = len(row)-1;\n",
    "print(num_input)\n",
    "\n",
    "####################################################\n",
    "#\n",
    "# This code is written with the help of the demo:\n",
    "# https://medium.com/@benjamin.phillips22/simple-regression-with-neural-networks-in-pytorch-313f06910379\n",
    "#\n",
    "####################################################\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "\n",
    "torch.manual_seed(1)    # reproducible\n",
    "\n",
    "x = torch.tensor(input_).float()  \n",
    "y = torch.tensor(output_).float()   \n",
    "new_shape = (len(y), 1)\n",
    "y = y.view(new_shape)\n",
    "\n",
    "\n",
    "i_val = torch.tensor(i_val).float()  \n",
    "o_val = torch.tensor(o_val).float()   \n",
    "new_shape = (len(o_val), 1)\n",
    "o_val = o_val.view(new_shape)\n",
    "\n",
    "\n",
    "\n",
    "max_y = torch.max(y[:,0])\n",
    "min_y =torch.min(y[:,0])\n",
    "\n",
    "max_x = torch.max(x,dim=0)\n",
    "min_x = torch.min(x,dim=0)\n",
    "\n",
    "print(max_y, min_y, max_x.values, min_x.values)\n",
    "\n",
    "range_y = max_y - min_y\n",
    "range_x = max_x.values - min_x.values\n",
    "\n",
    "print(range_x, range_y)\n",
    "\n",
    "    #Normalizing\n",
    "x = (x - min_x.values)/range_x\n",
    "y = (y - min_y)/range_y\n",
    "\n",
    "    #Normalizing\n",
    "i_val = (i_val - min_x.values)/range_x\n",
    "o_val = (o_val - min_y)/range_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-increase",
   "metadata": {
    "papermill": {
     "duration": 0.011087,
     "end_time": "2022-04-17T03:09:42.079839",
     "exception": false,
     "start_time": "2022-04-17T03:09:42.068752",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prediction NN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "funny-pharmaceutical",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T03:09:42.110238Z",
     "iopub.status.busy": "2022-04-17T03:09:42.109394Z",
     "iopub.status.idle": "2022-04-17T03:10:30.665726Z",
     "shell.execute_reply": "2022-04-17T03:10:30.665001Z",
     "shell.execute_reply.started": "2022-04-16T01:01:34.408798Z"
    },
    "papermill": {
     "duration": 48.575687,
     "end_time": "2022-04-17T03:10:30.665891",
     "exception": false,
     "start_time": "2022-04-17T03:09:42.090204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (hidden): Linear(in_features=3, out_features=500, bias=True)\n",
      "  (hidden2): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (predict): Linear(in_features=500, out_features=1, bias=True)\n",
      ")\n",
      "Epoch [200/600], Loss: 0.0133, Minimum Loss 0.012997, Val Loss 0.015020  \n",
      "Epoch [400/600], Loss: 0.0060, Minimum Loss 0.005954, Val Loss 0.006948  \n",
      "Epoch [600/600], Loss: 0.0054, Minimum Loss 0.004941, Val Loss 0.005750  \n"
     ]
    }
   ],
   "source": [
    "# torch can only train on Variable, so convert them to Variable\n",
    "x, y = Variable(x), Variable(y)\n",
    " \n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n",
    "        self.hidden2 = torch.nn.Linear(n_hidden, n_hidden)   # hidden layer\n",
    "        self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x\n",
    "\n",
    "# use the same net as before      \n",
    "net = Net(n_feature=num_input, n_hidden=500, n_output=1)     # define the network\n",
    "print(net)  # net architecture\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.05)\n",
    "loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss\n",
    "\n",
    "\n",
    "minimum_train_loss = 1e5\n",
    "minimum_val_loss = 1e5\n",
    "EPOCH = 600\n",
    "\n",
    "# start training\n",
    "for epoch in range(EPOCH):\n",
    "  \n",
    "    prediction = net(x)     # input x and predict based on x\n",
    "\n",
    "    loss = loss_func(prediction, y)     # must be (1. nn output, 2. target)\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    loss.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients\n",
    "    \n",
    "    if loss<minimum_train_loss:\n",
    "        minimum_train_loss =loss\n",
    "        net_opt = net\n",
    "    \n",
    "    if epoch%200 == 199:\n",
    "      prediction = net_opt(i_val)\n",
    "      loss_val = loss_func(prediction, o_val)\n",
    "      if loss_val<minimum_val_loss:\n",
    "        minimum_val_loss = loss_val\n",
    "        net_opt_val = net_opt\n",
    "      print (\"Epoch [{}/{}], Loss: {:.4f}, Minimum Loss {:.6f}, Val Loss {:.6f}  \"  .format(epoch+1, EPOCH, loss, minimum_train_loss, minimum_val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-sodium",
   "metadata": {
    "papermill": {
     "duration": 0.010792,
     "end_time": "2022-04-17T03:10:30.687828",
     "exception": false,
     "start_time": "2022-04-17T03:10:30.677036",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Computing Test Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "smooth-court",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T03:10:30.713841Z",
     "iopub.status.busy": "2022-04-17T03:10:30.713094Z",
     "iopub.status.idle": "2022-04-17T03:10:31.176022Z",
     "shell.execute_reply": "2022-04-17T03:10:31.175412Z",
     "shell.execute_reply.started": "2022-04-16T01:02:22.382726Z"
    },
    "papermill": {
     "duration": 0.477264,
     "end_time": "2022-04-17T03:10:31.176174",
     "exception": false,
     "start_time": "2022-04-17T03:10:30.698910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Test Loss 0.005750177\n",
      "Test Loss 0.048549186\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "i_test=[]\n",
    "o_test=[]\n",
    "for row in val_df.iloc:\n",
    "    i_test.append((row[0:len(row)-1]).astype(float))\n",
    "    o_test.append(row[-1])\n",
    "\n",
    "\n",
    "   \n",
    "i_test, o_test = Variable(torch.tensor(i_test)).float(), Variable(torch.tensor(o_test).float())\n",
    "new_shape = (len(o_test), 1)\n",
    "o_test = o_test.view(new_shape)\n",
    "\n",
    "    #Normalizing\n",
    "i_test = (i_test - min_x.values)/range_x\n",
    "o_test = (o_test - min_y)/range_y\n",
    "\n",
    "prediction = net_opt_val(i_test)\n",
    "loss_test = loss_func(prediction, o_test)\n",
    "\n",
    "print(\"Normalized Test Loss\",loss_test.detach().numpy())\n",
    "\n",
    "loss_test = loss_test*range_y*range_y # As the loss function returns MSE\n",
    "\n",
    "print(\"Test Loss\",loss_test.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-upper",
   "metadata": {
    "papermill": {
     "duration": 0.011087,
     "end_time": "2022-04-17T03:10:31.199043",
     "exception": false,
     "start_time": "2022-04-17T03:10:31.187956",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Minimim deviation based similarity finding for Uncertainty Bounds\n",
    "\n",
    "   Aim: To achieve all indexes of similar samples\n",
    "\n",
    "   Steps: \n",
    "\n",
    "1. Itertion over all Input combinations.\n",
    "\n",
    "2. Find all deviation by indexes \n",
    "   (sensitivity can be considered during the consideration of deviation)\n",
    "\n",
    "3. Save top 100 similar events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "american-concentrate",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T03:10:31.237730Z",
     "iopub.status.busy": "2022-04-17T03:10:31.236990Z",
     "iopub.status.idle": "2022-04-17T03:29:34.047809Z",
     "shell.execute_reply": "2022-04-17T03:29:34.048348Z"
    },
    "papermill": {
     "duration": 1142.83649,
     "end_time": "2022-04-17T03:29:34.048556",
     "exception": false,
     "start_time": "2022-04-17T03:10:31.212066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 %  Complete\n",
      "4.0 %  Complete\n",
      "8.0 %  Complete\n",
      "12.0 %  Complete\n",
      "16.0 %  Complete\n",
      "20.0 %  Complete\n",
      "24.0 %  Complete\n",
      "28.000000000000004 %  Complete\n",
      "32.0 %  Complete\n",
      "36.0 %  Complete\n",
      "40.0 %  Complete\n",
      "44.0 %  Complete\n",
      "48.0 %  Complete\n",
      "52.0 %  Complete\n",
      "56.00000000000001 %  Complete\n",
      "60.0 %  Complete\n",
      "64.0 %  Complete\n",
      "68.0 %  Complete\n",
      "72.0 %  Complete\n",
      "76.0 %  Complete\n",
      "80.0 %  Complete\n",
      "84.0 %  Complete\n",
      "88.0 %  Complete\n",
      "92.0 %  Complete\n",
      "96.0 %  Complete\n",
      "100% Complete in 18m 12s\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pickle as pkl\n",
    "import time\n",
    "\n",
    "\n",
    "Similar_event_count = 100\n",
    "sensitivity_consideration = 1\n",
    "max_dev_index = np.zeros(shape=(len(x),2))\n",
    "Similarity = np.zeros(shape=(len(x),Similar_event_count+1))\n",
    "sensitivity = max_x.values - min_x.values # just initializing a variable of that size\n",
    "iter_debug = 0\n",
    "since = time.time()\n",
    "\n",
    "for iter1 in range(len(x)):\n",
    "    current_input = x[iter1,:];\n",
    "    \n",
    "    if sensitivity_consideration == 1:\n",
    "        current_output = net_opt_val(current_input);\n",
    "        \n",
    "       # Determining Sensitivity\n",
    "        for iter2 in range(len(current_input)): \n",
    "            #print('Before Change',current_input)\n",
    "            current_input[iter2] = current_input[iter2] + range_x[iter2]/1e4;\n",
    "            #print('After Change',current_input)\n",
    "            sensitivity[iter2] = torch.abs(current_output - net_opt_val(current_input));\n",
    "            current_input[iter2] = current_input[iter2] - range_x[iter2]/1e4;\n",
    "        \n",
    "        sensitivity = sensitivity/torch.max(sensitivity); \n",
    "        #The highest sensitivity is considered one\n",
    "    \n",
    "    for iter2 in range(len(x)):\n",
    "        max_dev_index[iter2][0] = torch.max(sensitivity*torch.abs(current_input-x[iter2,:])/range_x).detach().numpy()\n",
    "        max_dev_index[iter2][1] = iter2\n",
    "        \n",
    "    sort_dev_index = max_dev_index[np.argsort(max_dev_index[:, 0])]\n",
    "    Similarity_threshold = sort_dev_index[Similar_event_count][0]\n",
    "    matched_indexes = sort_dev_index[0:Similar_event_count,1]\n",
    "    \n",
    "    Similarity[iter1,0] = Similarity_threshold\n",
    "    Similarity[iter1,1:(Similar_event_count+1)] = matched_indexes\n",
    "    \n",
    "    if iter1%200==0:   \n",
    "        print(iter1/len(x)*100, '%' '  Complete')\n",
    "        time_elapsed = time.time() - since\n",
    "        # Observing progres in Command Window\n",
    "        # May Take about hours to find all similar events for entire training data\n",
    "\n",
    "print('100% Complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))    \n",
    "\n",
    "fileName = './' + 'Similarity'\n",
    "fileObject = open(fileName, 'wb')\n",
    "\n",
    "pkl.dump(Similarity, fileObject)\n",
    "fileObject.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sharing-eagle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-17T03:29:34.092100Z",
     "iopub.status.busy": "2022-04-17T03:29:34.091409Z",
     "iopub.status.idle": "2022-04-17T03:29:34.094143Z",
     "shell.execute_reply": "2022-04-17T03:29:34.094607Z"
    },
    "papermill": {
     "duration": 0.027166,
     "end_time": "2022-04-17T03:29:34.094800",
     "exception": false,
     "start_time": "2022-04-17T03:29:34.067634",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Scripts for loading\n",
    "#ileObject2 = open(fileName, 'wb')\n",
    "#Test_array = pkl.load(fileObject2)\n",
    "#fileObject2.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1203.128294,
   "end_time": "2022-04-17T03:29:35.727754",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-17T03:09:32.599460",
   "version": "2.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
